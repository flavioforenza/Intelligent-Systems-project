\section{An End-to-End Multi-Task and Fusion CNN for Inertial-Based Gait Recognition}

\begin{flushleft}
    \author{
    Rubén Delgrado-Esca$ \tilde{n} $o,
    Francisco M. Castro,
    Julián Ramos Cózar,
    Manuel J. Marín-Jiménez,
    and Nicolás Guil
    }
\end{flushleft}

\begin{center}
    \emph{IEEE DIGITAL OBJECT IDENTIFIER}
\end{center}

\subsection{INTRODUCTION}
An individual's gait appears as their own fingerprint. The study of this 
topic doesn't not only concern the area of medicine, but also that of security 
and identification. The gating study is based on a non-invasive system that 
collects patterns without the direct intervention of the subject. The data, 
which allow the recognition of the gait, are taken by inertial sensors present 
in a multitude of devices such as smartphones or smartwatches. A system 
is presented that uses a convolutional neural network (CNN) that uses the 
data collected by these inertial sensors to be able to predict the subject. The 
approach followed is the one in figure \ref{fig:preview}. Two extensions have been added 
to the network. The first deals with merging sensory data, while the second 
deals with improving the learning process and producing multiple outputs 
from a single input, thanks to a multi-task scheme. The tasks considered 
are: identification, gender recognition and age estimation. The dataset used 
is OU-ISIR gait database \cite{0857651721}, containing information such as inertial sensors 
such as accelerometers and gyroscopes.
\begin{figure}[htbp]
    \centering
    \includegraphics[width = 0.6 \linewidth]{images/paper5/usecase.png}
    \centering
    \caption{A preview of how the model works.}
    \label{fig:preview}
\end{figure}

\subsection{RELATED WORK}
Some methods have placed inertial sensors in different parts of the body 
such as legs \cite{0857651733}, hips \cite{0857651732}, ankles, or even in objects such as bags [35] and 
pockets \cite{0857651720}. Other methods \cite{0857651736} directly use all the inertial sensors present 
in the smartphone. With the advent of deep learning and CNNs, classifying 
an activity has turned out to be an easier job. The input provided to these 
networks is either the raw data of the inertial sensors, or the images that 
represented such data. The entire sequence of data is divided into segments, 
or windows, in order not to negatively affect the performance of the network. 
In the following work, a union of all the data produced by inertial sensors is 
carried out with the multi-task approach in order to provide a single model 
that uses different inputs to produce different outputs.

\subsection{PROPOSED APPROACH}
\subsubsection{Problem definition}
The proposed neural network is able to automatically extract the discriminat 
features from a gait sequence. There is no data pre-processing phase. The 
dataset used contains three labels for each fetature, indicating the age, years 
and gender of the subject, but in addition to this, any type of dataset with 
labels and sensory data would have been fine. In the following paper the 
following nomenclature will be used:
\begin{itemize}
    \item {\bfseries{\emph{S}}}: input temporal sequence of \emph{D} channel measurements taken by a sensor.
    \item {\bfseries{$ s_i $}}: sub-sequence of \emph{S} having length \emph{L}, given as input to CNN.
    \item $ y_i^t $: label of the sub-sequence $ s_i $ and taskt \emph{t}.
    \item $ g(s_i, \theta ) $: non-linear function applied to $ s_i $ with a set of parameters $ \theta $.
    \item {\bfseries{$ \hat{y_i} $}}: output of the network for a given $ s_i $ input.
\end{itemize}

\subsubsection{Initial CNN Architecture}
