\section{Coarse-to-Fine Semantic Segmentation From Image-Level Labels}

\begin{flushleft}
    \author{
    Longlong Jing,
    Yucheng Chen,
    Yingli Tan,
    \emph{Fellow, IEEE}
    }
\end{flushleft}

\begin{center}
    \emph{IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL.29, 2020}
\end{center}

\subsection{INTRODUCTION}
To obtain a semantic segmentation it is necessary to have an annotated 
training set. Semantic segmentation generally requires pixel-wise semantic 
annotation techniques which are time-consuming. To solve the annotation 
problem, weakly supervised and semi-supervised semantic segmentation 
methods have been proposed. Methods such as object-level labels and image-level 
labels are used to extract annotations. These annotations are useful for 
producing datasets useful for training a weakly supervised model, such as 
the one proposed. By training a weakly supervised semantic segmentation 
model, with the labels produced, the performances match those of the supervised 
methods. Unfortunately, methods such as object-level labels produce 
bounding boxes that are still not precise, so the use of the image-level labels 
method prevails. The dataset used is that of ImageNet where a category is 
associated with each image. The proposed model is able to generate as many 
segmentation masks as there are different objects belonging to different 
categories in each image. Network training takes place using information such as 
masks, images and labels of each category. An example of the coarse-to-fine 
mask produced by the model is the one shown in figure \ref{fig:semanticWork}.
\begin{figure}[h!]
    \centering
    \includegraphics[width = 1 \linewidth]{images/paper6/work.png}
    \centering
    \caption{Example of semantic segmentation generated by the proposed method.}
    \label{fig:semanticWork}
\end{figure}

\subsection{RELATED WORK}
\subsubsection{Semantic Segmentation}
There are three different types of semantic segmentation methods that differ 
based on the level of annotation used:
\begin{enumerate}
    \item \emph{Fully Supervised Pixel-Wise Annotation-Based Methods}: trained with 
    pixel-wise labels annotated by people:
    \item \emph{Weakly Supervised Object-level Annotation-Based-Methods}: trained with 
    methods such as object-level annotations based on the use of bounding 
    boxes;
    \item \emph{Weakly Supervised Image-Level Annotation-Based Methods}: trained 
    with image category labels.
\end{enumerate}
The methods in the first point, if trained with precise labels, are able to 
obtain the best performances.

\subsubsection{Foreground Segmentation}
The labels assigned to pixels can be useful to separate a foreground object 
from a background object. Also for this task there are three strategies to 
perform a segmentation of the objects in the foreground:
\begin{enumerate}
    \item \emph{Joint segmentation-based Methods}: used prior knowledge as supervision.
    \item \emph{Saliency prediction-based Methods}: identify regions present in the human 
    visual scene.
    \item \emph{Object proposal-based Methods}: locate all objects in images.
\end{enumerate}
The proposed framework can also be used for this purpose.

\subsection{THE PROPOSED APPROACH}
\subsubsection{Overview}
The work performed by the model is divided into three steps: \emph{coarse mask 
generation}, \emph{coarse mask enhancement}, and \emph{Recursive mask refinement} (Fig. \ref{fig:step}). In 
order to generate the initial masks, a CNN is trained and subsequently these 
are improved with a graph-based model. Images, enhanced masks and lables 
are used to train the model.
\begin{figure}[h!]
    \centering
    \includegraphics[width = 1 \linewidth]{images/paper6/step.png}
    \centering
    \caption{Steps of the proposed method.}
    \label{fig:step}
\end{figure}

\subsubsection{Coarse Mask Generation}
The generation of a mask must occur without any information on the labels.
The CNN present in \cite{0876055520} is used for this purpose. This network is trained 
with millions of unlabeled images and is also the fastest of other methods 
existing in the state of the art. Unfortunately, as seen in image \ref{fig:semanticWork}, the 
generated coarse masks appear to be inaccurate and do not correspond with 
the position of the underlying object.

\subsubsection{Coarse Mask Enhancement}
The enhancement of the mask is done before the net training process takes 
place. To carry out the improvement, the unsupervised GrubCut model \cite{0876055542} 
is used. This method performs segmentations that divide the background 
from the foreground using a Gaussian Mixture model to estimate the color 
distribution of objects. These distributions are used to construct a Markov 
Random Field on the labels of each pixel. A graph cut optimization has the 
task of maximizing the search for connected regions having the same label. 
There are two steps to apply the GrabCut:
\begin{enumerate}
    \item search for the smallest bounding box inside the mask.
    \item enhance the mask based on the previously created bounding box and on the RGB image.
\end{enumerate}
The enhanced mask will be used to recursively train the network.