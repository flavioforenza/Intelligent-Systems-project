\section{Paper 6}
\subsection{\emph{"Coarse-to-Fine Semantic Segmentation From Image-Level Labels"}}

\begin{frame}{INTRODUCTION}
    Weakly supervised and semi-supervised methods are used to achieve 
    semantic segmentation. These methods need techniques that are capable 
    of producing useful labels in order to train the models. Two types of 
    techniques that produce labels are: \emph{Image-level labels} (categories) and 
    \emph{Object-level labels} (bounding boxes). In the following paper, the use of 
    the first technique prevails over the second because it is more accurate. 
    The proposed framework has the task of training a model that only 
    depends on image category level annotations. The final goal is to be able 
    to recognize different objects, in the foreground, belonging to different 
    categories.
\end{frame}

\begin{frame}{RELATED WORK}
    The following framework can be used for both semantic segmentation 
    and foreground object segmentation. There are various models proposed 
    at the state of the art that carry out a different semantic segmentation 
    and a different foreground segmentation.
    \begin{table}[h!]
        \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{|p{6cm}|p{6cm}|}
            \hline
            \centering
            \bfseries{Semantic Segmentation Methods} &  ~\bfseries{Foreground Segmentation Methods} \\
            \hline
            \begin{enumerate}
                \item \emph{Fully Supervised Pixel-Wise Annotation-Based Methods}: trained with 
                pixel-wise labels annotated by people.
                \item \emph{Weakly Supervised Object-level Annotation-Based-Methods}: trained with 
                methods such as object-level annotations based on the use of bounding 
                boxes.
                \item \emph{Weakly Supervised Image-Level Annotation-Based Methods}: trained 
                with image category labels.
            \end{enumerate}
            & 
            \begin{enumerate}
                \item \emph{Joint segmentation-based Methods}: used prior knowledge as supervision.
                \item \emph{Saliency prediction-based Methods}: identify regions present in the human 
                visual scene.
                \item \emph{Object proposal-based Methods}: locate all objects in images.
            \end{enumerate}\\
            \hline
        \end{tabular}
        \end{adjustbox}
    \end{table}
\end{frame}

\begin{frame}{THE PROPOSED APPROACH - 3 Steps}
    The work performed by the model is divided into three steps: \emph{coarse mask generation}, \emph{coarse mask enhancement}, and \emph{recursive mask refinement}.
    \begin{figure}[h!]
        \centering
        \includegraphics[width = 1 \linewidth]{images/paper6/step.png}
        \centering
        \caption{Steps of the proposed method.}
    \end{figure}
\end{frame}

\begin{frame}{THE PROPOSED APPROACH - \emph{Coarse Mask Generation}}
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.45\linewidth}
            A CNN network\footnotemark ~is used to be able 
            to extract a first coarse mask. 
            Unfortunately, as can be seen in 
            the image, the generated masks 
            appear to be inaccurate and do 
            not comply with the position of 
            the underlying object.
        \end{minipage}
        \hspace{0.05\linewidth}
        \begin{minipage}{0.45\linewidth}
            \begin{figure}[h!]
                \centering
                \includegraphics[width = 1 \linewidth]{images/paper6/coarse mask.png}
                \centering
            \end{figure}
        \end{minipage}
    \end{minipage}
    \footnotetext{I. Croitoru, S.-V. Bogolin, and M. Leordeanu, “Unsupervised learning from video to detect foreground objects in single images,” in Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Oct. 2017, pp. 4335–4343.}
\end{frame}

\begin{frame}{THE PROPOSED APPROACH - \emph{Coarse Mask Enhancement}}
    To carry out the enhanced coarse mask, the unsupervised GrubCut 
    model\footnotemark ~is used. To achieve mask optimization, the 
    method performs the following two steps:
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.45\linewidth}
            \begin{enumerate}
                \item search for the smallest bounding box inside the mask.
                \item enhance the mask based on the previously created bounding box and on the RGB image.
            \end{enumerate}
        \end{minipage}
        \hspace{0.05\linewidth}
        \begin{minipage}{0.45\linewidth}
            \begin{figure}[h!]
                \centering
                \includegraphics[width = 1.2 \linewidth]{images/paper6/enhancement.png}
                \centering
            \end{figure}
        \end{minipage}
    \end{minipage}
    \footnotetext{C. Rother, V. Kolmogorov, and A. Blake, “GrabCut: Interactive foreground extraction using iterated graph cuts,” ACM Trans. Graph., vol. 23, no. 3, pp. 309–314, 2004.}
\end{frame}

\begin{frame}{THE PROPOSED APPROACH - \emph{Recursive Mask Refinement}}
    A network called DeepLab \footfullcite{0876055502} is used for semantic segmentation. This 
    network uses the mask generated by the GrubCut method and, through a 
    comparison on the original image, produces a new better mask that will 
    be used as a new training set. The best mask will be obtained after a 
    maximum of 5 training rounds.
    \begin{figure}[h!]
        \centering
        \includegraphics[width = 1 \linewidth]{images/paper6/DeepLab.png}
        \centering
    \end{figure}
\end{frame}

\begin{frame}{EXPERIMENTS - Semantic Segmentation Results}
    The \emph{Intersection over Union} (IoU), averaged over 21, categories is used as an 
    evaluation index of the semantic segmentation and foreground segmentation. 
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.45\linewidth}
            \begin{table}[h!]
                \centering
                \begin{adjustbox}{max width=0.7\textwidth}
                \begin{tabular}{|c|c|}
                    \hline
                    Training Mask Type & IoU(\%)\\
                    \hline
                    Coarse Masks & 32.5 \\
                    Bounding Boxes & 35.2 \\
                    Enhanced Masks & 47.7 \\
                    Refined Masks & 50.4 \\
                    \hline
                \end{tabular}
                \end{adjustbox}
                \caption{The performance of semantic segmentation networks evalueted in the validation split of PASCAL VOC dataset in the mean IoU (higher is better).}
            \end{table}
        \end{minipage}
        \hspace{0.05\linewidth}
        \begin{minipage}{0.45\linewidth}
            \begin{figure}[h!]
                \centering
                \includegraphics[width = 1 \linewidth]{images/paper6/GrabCut.png}
                \centering
                \caption{Enhancement with GrubCut application}
            \end{figure}
        \end{minipage}
    \end{minipage}
    \begin{table}[h!]
        \centering
        \begin{adjustbox}{max width=0.7\textwidth}
        \begin{tabular}{|c|c|c|}
            \hline
            Methods & mIoU(val) & mIoU(test)\\
            \hline
            Supervision: Object-level Labels & &\\
            SDI \cite{0876055513} & 65.7 & 67.5\\
            \hline
            Supervision: Image-level Labels & &\\
            Bootstrap \cite{0876055555} & 63.0 & 63.9\\
            \bfseries{The proposed weakly supervised method} & \bfseries{61.9} & \bfseries{62.8}\\
            \hline
        \end{tabular}
        \end{adjustbox}
        \caption{Comparison, in terms of IoU score, between different models.}
        \label{IoU score comparison}
    \end{table}
\end{frame}

\begin{frame}{EXPERIMENTS - Foreground Segmentation Results}
    With an architecture similar to \emph{FPN} \footfullcite{0876055543}, the new network is called the \emph{Dilated Feature Pyramid 
    Network} (DFPN). This network has several dilated layers, in three branches, 
    added to enlarge the receptive field of the network. The features generated 
    by these layers are aggregated to make a prediction. From the performance obtained, the proposed 
    model, which is remembered to be weakly supervised, manages to achieve the 
    performance of the supervised models, with a difference of 2.06\% compared 
    to the supervised \emph{PixelObjectness}.
    \begin{table}[h!]
        \centering
        \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{|c||c|c|c|c||c|c|c|c|}
            \hline
            \multirow{2}{*}{\bfseries{Methods}} & \multicolumn{4}{c||}{\bfseries{MIT dataset (subset)}} & \multicolumn{4}{c|}{\bfseries{MIT dataset (full)}} \\            & \bfseries{Ariplane} & \bfseries{Car} & \bfseries{Horse}  & \bfseries{Average} & \bfseries{Ariplane} & \bfseries{Car} & \bfseries{Horse}  & \bfseries{Average} \\
            \hline
            \bfseries{\#Images} & 82 & 89 & 93 & N/A & 470 & 1208 & 810 & N/A\\
            \hline
            UnsupervisedSeg \cite{0876055520} & 61.37 & 70.52 & 55.09 &62.32 & N/A & N/A & N/A & N/A\\
            \hline
            PixelObjectness \cite{0876055538} & 66.43 & 85.07 & 60.85 &70.78 & 66.18 & 84.80 & 64.90 & 71.96\\
            \hline 
            \bfseries{FPN-Baseline} & 61.09 & 76.22 & 57.89 & \bfseries{65.08} & 61.93 & 75.94 & 64.03 & \bfseries{67.3}\\
            \hline
            \bfseries{Proposed Method} & 64.92 & 77.60 & 60.36 & \bfseries{67.63(+2.57)} & 65.88 & 77.07 & 65.82 & \bfseries{69.59(+2.29)}\\
            \hline
        \end{tabular}
        \end{adjustbox}
        \caption{Quantitative Results of Foreground Segmentation on MIT object Discovery Dataset.}
    \end{table}
\end{frame}

\begin{frame}{CONCLUSION}
    The proposed framework, based on a weakly supervide model, is able to 
    achieve the performance of the full supervised models that obtain better 
    results at the state of the art. It is also capable of recognizing multiple categories of objects in an image (Fig. \ref{fig:segmentationCategories}). Despite the efforts made to arrive at such 
    results, there are several classes in which the model fails to generate 
    good masks (Fig. \ref{fig:classes}).
    \begin{figure}[h!]
        \centering
        \includegraphics[width = 0.6 \linewidth]{images/paper6/multiple segmentation.png}
        \centering
        \caption{Example of semantic segmentation on different categories.}
        \label{fig:segmentationCategories}
    \end{figure}
    \begin{figure}[h!]
        \centering
        \includegraphics[width = 1 \linewidth]{images/paper6/classes.png}
        \centering
        \caption{Score of IoU in some classes.}
        \label{fig:classes}
    \end{figure}
\end{frame}




